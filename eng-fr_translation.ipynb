{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "20f4f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchtext.data as ttd\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c2b8b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20_000\n",
    "NUM_SAMPLES = 10_000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 256\n",
    "\n",
    "SOS = \"<sos>\"\n",
    "EOS = \"<eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e19e50e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "input_texts = []  # sentence in original language\n",
    "target_texts = []  # sentence in target language\n",
    "target_text_inputs = []  #  sentence in target language offset by 1\n",
    "t = 0\n",
    "for line in open(\"./fra.txt\"):\n",
    "    # only keep a limited number of samples\n",
    "    t += 1\n",
    "    if t > NUM_SAMPLES:\n",
    "        break\n",
    "    line = line.rstrip()\n",
    "    # input and targets are separeted by tab\n",
    "    if \"\\t\" not in line:\n",
    "        continue\n",
    "\n",
    "    # split up the input and translation\n",
    "    input_text, translation = line.split(\"\\t\")[:2]\n",
    "\n",
    "    # make the target input and output\n",
    "    # we'll be using teacher forcing\n",
    "    #target_text = translation + \" <eos>\"\n",
    "    #target_text_input = \"<sos> \" + translation\n",
    "\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(translation)\n",
    "    #target_text_inputs.append(target_text_input)\n",
    "print(\"num samples:\", len(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07dad6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I forbid that.\n",
      "Ne me pousse pas !\n"
     ]
    }
   ],
   "source": [
    "# some checks\n",
    "idx = np.random.randint(len(input_texts))\n",
    "print(input_texts[idx])\n",
    "\n",
    "idx = np.random.randint(len(target_texts))\n",
    "print(target_texts[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af2fa1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocab\n",
    "voc = []\n",
    "voc_fr = [EOS, SOS]\n",
    "#stop_words = stopwords.words(\"english\")\n",
    "\n",
    "for line in input_texts:\n",
    "    line = word_tokenize(re.sub(\"\\W+\", \" \", line.lower())) \n",
    "    for w in line:\n",
    "        if w not in voc: # and w not in stop_words:\n",
    "            voc.append(w)\n",
    "            \n",
    "for line in target_texts:\n",
    "    line = word_tokenize(re.sub(\"\\W+\", \" \", line.lower())) \n",
    "    for w in line:\n",
    "        if w not in voc_fr: # and w not in stop_words:\n",
    "            voc_fr.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67cd34b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocab : 1999 tokens\n"
     ]
    }
   ],
   "source": [
    "# convert vocabulary to indices and keep the order \n",
    "word2idx = {}\n",
    "for idx, w in enumerate(voc):\n",
    "    word2idx[w] = idx + 1 # key=word, item=index\n",
    "\n",
    "word2idx_keys = word2idx.keys()\n",
    "print(\"Length of vocab : {0:d} tokens\".format(len(word2idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31f4a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocab : 3932 tokens\n"
     ]
    }
   ],
   "source": [
    "# convert vocabulary to indices and keep the order \n",
    "word2idx_fr = {}\n",
    "for idx, w in enumerate(voc_fr):\n",
    "    word2idx_fr[w] = idx + 1 # key=word, item=index\n",
    "\n",
    "word2idx_fr_keys = word2idx_fr.keys()\n",
    "print(\"Length of vocab : {0:d} tokens\".format(len(word2idx_fr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a098188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing inputs and targets\n",
    "input_sequences = []\n",
    "target_sequences = []\n",
    "target_sequences_inputs = []\n",
    "\n",
    "for line in input_texts:\n",
    "    line = word_tokenize(re.sub(\"\\W+\", \" \", line.lower())) \n",
    "    input_sequence = [word2idx[w] for w in line]\n",
    "    input_sequences.append(input_sequence)\n",
    "    \n",
    "\n",
    "for line in target_texts:\n",
    "    line = word_tokenize(re.sub(\"\\W+\", \" \", line.lower())) \n",
    "    sequence = [word2idx_fr[w] for w in line] \n",
    "    target_sequence = sequence + [word2idx_fr[EOS]]\n",
    "    target_sequence_input = [word2idx_fr[SOS]] + sequence\n",
    "    target_sequences.append(target_sequence)\n",
    "    target_sequences_inputs.append(target_sequence_input)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3193e084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([132, 2481, 1927, 1], [2, 132, 2481, 1927])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity checks\n",
    "target_sequences[-1], target_sequences_inputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ca3910c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len_input: 5\n",
      "max_len_target: 13\n"
     ]
    }
   ],
   "source": [
    "# determine maximum length input/target sequence\n",
    "max_len_input = max(len(s) for s in input_sequences)\n",
    "print(\"max_len_input:\", max_len_input)\n",
    "\n",
    "max_len_target = max(len(s) for s in target_sequences)\n",
    "print(\"max_len_target:\", max_len_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d82dd59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pad the sequences\n",
    "def pad_sequences(sequences, maxlen, padding='pre'):\n",
    "    seq = sequences.copy()\n",
    "    if padding == 'post':\n",
    "        for i in range(len(sequences)):\n",
    "            if len(sequences[i]) < maxlen:\n",
    "                seq[i] += (maxlen - len(sequences[i])) * [0]\n",
    "    elif padding == 'pre':\n",
    "        for i in range(len(sequences)):\n",
    "            if len(sequences[i]) < maxlen:\n",
    "                seq[i] = (maxlen - len(sequences[i])) * [0] + sequences[i]\n",
    "    \n",
    "    seq = np.array(seq)\n",
    "    return seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4baab485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_data.shape: 10000 5\n",
      "encoder_data[0]: [0 0 0 0 1]\n",
      "decoder_data.shape: 10000 13\n",
      "decoder_data[0]: [2 3 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_data.shape:\", len(encoder_inputs),len(encoder_inputs[0]) )\n",
    "print(\"encoder_data[0]:\", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(\n",
    "    target_sequences_inputs, maxlen=max_len_target, padding=\"post\"\n",
    ")\n",
    "print(\"decoder_data.shape:\", len(decoder_inputs),len(decoder_inputs[0]))\n",
    "print(\"decoder_data[0]:\", decoder_inputs[0])\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00940ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word vectors ...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load in pre-trained word vectors \n",
    "# can download here \n",
    "# word2vec = torchtext.vocab.GloVe(name=\"6B\", dim=EMBEDDING_DIM) \n",
    "print(\"loading word vectors ...\")\n",
    "word2vec_path = '../../Lazyprogrammer/large_files/glove.6B/glove.6B.%sd.txt'\n",
    "word2vec = {}\n",
    "with open(\n",
    "    os.path.join(word2vec_path % EMBEDDING_DIM)\n",
    ") as f:\n",
    "    # is just a space-separated text file in the format:\n",
    "    # word vec[0] vec[1] vec[2]\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.array(values[1:], dtype=\"float32\")\n",
    "        word2vec[word] = vec\n",
    "    print(\"Found %s word vectors.\" % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dba36d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print(\"Filling pre-trained embeddings...\")\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i < num_words:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all zeros\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "62bcd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store number of output wors for later\n",
    "# remember to add 1 since indexing start at 1\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "# one-hot the targets \n",
    "decoder_targets_one_hot = np.zeros(\n",
    "    (len(input_sequences), max_len_target, num_words_output), dtype='float32'\n",
    ")\n",
    "for i, d in enumerate(decoder_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d3ccb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word embeddings into an embedding layer\n",
    "# freeze the layer\n",
    "embedding_layer = nn.Embedding(num_words, EMBEDDING_DIM,)  # vocab size  # embedding dim\n",
    "embedding_layer.weight = nn.Parameter(torch.from_numpy(embedding_matrix).float())\n",
    "#embedding_layer.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e29efe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(max_len_input)\n",
    "print(max_len_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T_encoder = 5\n",
    "# T_decoder = 13\n",
    "# encoder_input size N x 5\n",
    "# decoder_input size N x 13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b10a89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.encoder = nn.LSTM(input_size=EMBEDDING_DIM, hidden_size=LATENT_DIM, batch_first=True) # -> N x T x LATENT_DIM \n",
    "        self.embed = embedding_layer\n",
    "        self.embed_decoder = nn.Embedding(num_words_output, EMBEDDING_DIM) # vocab_size_output X Latent Dim \n",
    "        self.decoder = nn.LSTM(input_size=EMBEDDING_DIM, hidden_size=LATENT_DIM, batch_first=True)\n",
    "        self.fc = nn.Linear(LATENT_DIM, num_words_output)\n",
    "        \n",
    "    def forward(self, X_encoder, X_decoder):\n",
    "        h0 = torch.zeros(1, X_encoder.size(0), LATENT_DIM)#.to(device)\n",
    "        c0 = torch.zeros(1, X_encoder.size(0), LATENT_DIM)#.to(device)\n",
    "        \n",
    "        out = self.embed(X_encoder) # N x T_input -> N x T_encoder x EMBEDDING_DIM\n",
    "        _ , (h, c) = self.encoder(out, (h0, c0))  # (h, c) : ((1, N , LATENT_DIM), (1, N , LATENT_DIM))\n",
    "        \n",
    "        decoder_inputs_x = self.embed_decoder(X_decoder) # # N x T_decoder -> N x T_decoder x EMBEDDING_DIM\n",
    "        decoder_outputs, _ = self.decoder(decoder_inputs_x, (h, c)) # -> N x T_decoder x LATENT_DIM\n",
    "        \n",
    "        final_out = self.fc(decoder_outputs) # -> N x T_decoder x num_words_output\n",
    "        \n",
    "        return final_out\n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c4bedcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f9ce8a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13, 5681])\n"
     ]
    }
   ],
   "source": [
    "# simple test \n",
    "x_in = torch.ones(1,5, dtype=torch.int) \n",
    "x_out = torch.ones(1,13, dtype=torch.int) \n",
    "y = model(x_in, x_out)\n",
    "print(y.shape)\n",
    "#EMBEDDING_DIM = 100\n",
    "#LATENT_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d54f5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors \n",
    "encoder_inputs_tensor = torch.from_numpy(encoder_inputs).int()\n",
    "decoder_inputs_tensor = torch.from_numpy(decoder_inputs).int()\n",
    "decoder_targets_one_hot_tensor = torch.from_numpy(decoder_targets_one_hot).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d252b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data set\n",
    "class Translation(data.Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(encoder_inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return encoder_inputs_tensor[idx], decoder_inputs_tensor[idx], decoder_targets_one_hot_tensor[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "177b5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate dataset\n",
    "translation_dataset = Translation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "51766848",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=translation_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9e85e82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5]) torch.Size([64, 13]) torch.Size([64, 13, 5681])\n"
     ]
    }
   ],
   "source": [
    "for inputs, inputs_d, targets in data_loader:\n",
    "    print(inputs.shape, inputs_d.shape, targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1f569d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b59de285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3. Train Loss = 0.0033\n",
      "Epoch 2/3. Train Loss = 0.0033\n",
      "Epoch 3/3. Train Loss = 0.0033\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "#EPOCHS = 3\n",
    "# loss to store\n",
    "train_losses = np.zeros(EPOCHS)\n",
    "test_losses = np.zeros(EPOCHS)\n",
    "\n",
    "for it in range(EPOCHS):\n",
    "\n",
    "    train_loss = []\n",
    "    for inputs_encoder, inputs_decoder, targets in data_loader:\n",
    "        # move data to gpu\n",
    "        #inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(inputs_encoder, inputs_decoder)\n",
    "\n",
    "        # compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # zero the grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # store loss\n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    # final loss\n",
    "    train_loss = np.mean(train_loss)\n",
    "    train_losses[it] = train_loss\n",
    "\n",
    "\n",
    "    # prints\n",
    "    print(f\"Epoch {it+1}/{EPOCHS}. Train Loss = {train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0b0d6a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a sampling model\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "       \n",
    "    def forward(self, X_encoder):\n",
    "        # encoder_input size 1 x 5\n",
    "        h0 = torch.zeros(1, X_encoder.size(0), LATENT_DIM)#.to(device) \n",
    "        c0 = torch.zeros(1, X_encoder.size(0), LATENT_DIM)#.to(device)\n",
    "        \n",
    "        out = model.embed(X_encoder) # 1 x T_encoder -> 1 x T_encoder x EMBEDDING_DIM\n",
    "        _ , (h, c) = model.encoder(out, (h0, c0))  # (h, c) : ((1, 1 , LATENT_DIM), (1, 1 , LATENT_DIM))\n",
    "\n",
    "        return h, c\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "85676d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5b49b777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256]) torch.Size([1, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "# simple test \n",
    "x_in = torch.ones(1,1, dtype=torch.int) \n",
    "#x_out = torch.ones(1,13, dtype=torch.int) \n",
    "h, c = encoder(x_in)\n",
    "print(h.shape, c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9671a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a sampling model\n",
    "class SamplingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SamplingModel, self).__init__()\n",
    "        \n",
    "    \n",
    "    def forward(self, X_decoder, h, c):\n",
    "        # decoder_input size 1 x 13\n",
    "        # (h, c) : ((1, 1 , LATENT_DIM), (1, 1 , LATENT_DIM))\n",
    "        decoder_inputs_x = model.embed_decoder(X_decoder) # 1 x T_decoder -> 1 x T_decoder x EMBEDDING_DIM\n",
    "        out, (h, c) = model.decoder(decoder_inputs_x, (h, c)) # -> 1 x T_decoder x LATENT_DIM\n",
    "        out = model.fc(out) # -> 1 x T_decoder x NUM_words out\n",
    "        \n",
    "        return out, h, c\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "366225b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_model = SamplingModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "95efb79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 5681]) torch.Size([1, 1, 256]) torch.Size([1, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "# simple test \n",
    "#x_in = torch.ones(1,5, dtype=torch.int) \n",
    "x_out = torch.ones(1,1, dtype=torch.int) \n",
    "out, h, c = sampling_model(x_out, h, c)\n",
    "print(out.shape, h.shape, c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f6d22d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map indexes back into real words\n",
    "# so wwe can view the results\n",
    "idx2word_eng = {v: w for w, v in word2idx.items()}\n",
    "idx2word_fr = {v: w for w, v in word2idx_fr.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e3f6aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate empty target seq of length 1\n",
    "target_seq = torch.zeros((1, 1))\n",
    "\n",
    "# populate the first character of target sequence with the start character\n",
    "# NOTE: tokenizer lower cases all words\n",
    "target_seq[0, 0] = word2idx_outputs[\"<sos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3e1f5cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # encode the input as state vectors.\n",
    "    h, c = encoder(input_seq)\n",
    "\n",
    "    # generate empty target seq of length 1\n",
    "    target_seq = torch.zeros((1, 1)).int()\n",
    "\n",
    "    # populate the first character of target sequence with the start character\n",
    "    # NOTE: tokenizer lower cases all words\n",
    "    target_seq[0, 0] = word2idx_outputs[\"<sos>\"]\n",
    "\n",
    "    # if we get this we break\n",
    "    eos = word2idx_outputs[\"<eos>\"]\n",
    "\n",
    "    # create translation\n",
    "    output_sentence = []\n",
    "    for _ in range(max_len_target):\n",
    "        output_tokens, h, c = sampling_model(target_seq, h, c)\n",
    "\n",
    "        # get next word\n",
    "        idx = np.argmax(output_tokens.detach().numpy()[0, 0, :])\n",
    "\n",
    "        # end of sentence EOS\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        word = \"\"\n",
    "        if idx > 0:\n",
    "            word = idx2word_fr[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # update the decoder input\n",
    "        # which is just the word just generated\n",
    "        target_seq[0, 0] = idx\n",
    "        #states_value = [h, c]\n",
    "\n",
    "    return \" \".join(output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9a138829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([1.2423, 1.4502, 1.1779, 1.6262]),\n",
      "indices=tensor([3, 3, 0, 3]))\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,4)\n",
    "m = torch.max(x, 1)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e2df13cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0,   0, 610, 251,  56]], dtype=torch.int32), torch.Tensor)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do some translation\n",
    "i = np.random.choice(len(input_texts))\n",
    "input_seq = encoder_inputs_tensor[i : i + 1]\n",
    "input_seq, type(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "acb91201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: I saw that.\n",
      "Translation: j ai été du un\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: Tom grumbled.\n",
      "Translation: j adore l essayer\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: Tie your shoe.\n",
      "Translation: puis je m en\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: I'm a lawyer.\n",
      "Translation: j ai été du un\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: Get the box.\n",
      "Translation: puis je partir\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: Talk to me!\n",
      "Translation: puis je partir\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: Well done!\n",
      "Translation: puis je partir\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: I'll pay you.\n",
      "Translation: j ai été du un\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: You're naive.\n",
      "Translation: puis je m en\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: They're cute.\n",
      "Translation: j ai été du un\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: Can you ski?\n",
      "Translation: puis je m en aller\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: Bring the key.\n",
      "Translation: puis je partir\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: Straighten up.\n",
      "Translation: puis je partir\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # do some translation\n",
    "    i = np.random.choice(len(input_texts))\n",
    "    input_seq = encoder_inputs_tensor[i : i + 1]\n",
    "    translation = decode_sequence(input_seq)\n",
    "    print(\"_\")\n",
    "    print(\"Input:\", input_texts[i])\n",
    "    print(\"Translation:\", translation)\n",
    "\n",
    "    ans = input(\"Continue? [Y/n]\")\n",
    "    if ans and ans.lower().startswith(\"n\"):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d1c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
