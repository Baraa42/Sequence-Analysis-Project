{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "u5o0LxWg0cSM",
   "metadata": {
    "id": "u5o0LxWg0cSM"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ilLTMw8-Zk8J",
   "metadata": {
    "id": "ilLTMw8-Zk8J"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import sys, re, os\n",
    "import string, unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kwts_WwZaLGi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwts_WwZaLGi",
    "outputId": "54ee7867-73ba-485b-f85d-741391abaa15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FFCFabhL0y8m",
   "metadata": {
    "id": "FFCFabhL0y8m"
   },
   "source": [
    "# Google drive and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UHp6-Ovx6qr9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHp6-Ovx6qr9",
    "outputId": "5e660398-16ec-4253-a079-46dd32be6f5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PCZaWK726rM_",
   "metadata": {
    "id": "PCZaWK726rM_"
   },
   "outputs": [],
   "source": [
    "drive_path = \"/content/drive/MyDrive/Sequence-Analysis-Projects\"\n",
    "translation_path = os.path.join(drive_path, 'translation')\n",
    "if not os.path.exists(drive_path):\n",
    "    os.mkdir(drive_path)\n",
    "\n",
    "projects = ['translation', 'twitter-chatbot']\n",
    "for project in projects:\n",
    "    project_path = os.path.join(drive_path, project)\n",
    "    if not os.path.exists(project_path):\n",
    "        os.mkdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wabLRdcbAIfz",
   "metadata": {
    "id": "wabLRdcbAIfz"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df92808",
   "metadata": {
    "id": "9df92808"
   },
   "outputs": [],
   "source": [
    "# some configuration\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20_000\n",
    "NUM_SAMPLES = 150_000 # max_num = 192341 \n",
    "EMBEDDING_DIM = 100\n",
    "BATCH_SIZE = 64\n",
    "LATENT_DIM = 256\n",
    "\n",
    "bos = \"<bos>\"\n",
    "eos = \"<eos>\"\n",
    "pad = \"<pad>\"\n",
    "unk = \"<unk>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F8iSDWUO0658",
   "metadata": {
    "id": "F8iSDWUO0658"
   },
   "source": [
    "#Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_yYEu0G9nnkk",
   "metadata": {
    "id": "_yYEu0G9nnkk"
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-Czuo3npnzIZ",
   "metadata": {
    "id": "-Czuo3npnzIZ"
   },
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bMzFhg2H1Bex",
   "metadata": {
    "id": "bMzFhg2H1Bex"
   },
   "source": [
    "# Original Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bVt74Q_nfoy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bVt74Q_nfoy",
    "outputId": "7c223f8b-cb26-4271-f197-e5db6acd3015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 150000\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "input_texts = []  # sentence in original language\n",
    "target_texts = []  # sentence in target language\n",
    "t = 0\n",
    "for line in open(os.path.join(translation_path, \"fra.txt\")):\n",
    "    # only keep a limited number of samples\n",
    "    t += 1\n",
    "    if t > NUM_SAMPLES:\n",
    "        break\n",
    "    line = line.rstrip()\n",
    "    # input and targets are separeted by tab\n",
    "    if \"\\t\" not in line:\n",
    "        continue\n",
    "\n",
    "    # split up the input and translation\n",
    "    input_text, target_text = line.split(\"\\t\")[:2]\n",
    "    input_text, target_text = normalizeString(input_text), normalizeString(target_text)\n",
    "  \n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    \n",
    "print(\"num samples:\", len(input_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mlCxm7zDuVmc",
   "metadata": {
    "id": "mlCxm7zDuVmc"
   },
   "source": [
    "# Build train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2y3Sn6mGuZvG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2y3Sn6mGuZvG",
    "outputId": "19976f5b-ce1d-4220-d8fe-70eb681014b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_inputs): 120000\n",
      "len(test_inputs): 30000\n"
     ]
    }
   ],
   "source": [
    "N = len(input_texts)\n",
    "indices = np.random.permutation(N)\n",
    "\n",
    "N_train = 4 * N // 5\n",
    "\n",
    "train_indices = list(indices[:N_train])\n",
    "test_indices = list(indices[N_train:])\n",
    "\n",
    "train_inputs = [input_texts[i] for i in train_indices]\n",
    "train_targets = [target_texts[i] for i in train_indices]\n",
    "\n",
    "test_inputs = [input_texts[i] for i in test_indices]\n",
    "test_targets = [target_texts[i] for i in test_indices]\n",
    "\n",
    "\n",
    "print(\"len(train_inputs):\", len(train_inputs))\n",
    "print(\"len(test_inputs):\", len(test_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x7tx6LF51Y4f",
   "metadata": {
    "id": "x7tx6LF51Y4f"
   },
   "source": [
    "# Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HHifyrOmbUjy",
   "metadata": {
    "id": "HHifyrOmbUjy"
   },
   "outputs": [],
   "source": [
    "def build_vocab(data):\n",
    "    vocab = []\n",
    "    for sentence in data:\n",
    "        sentence_tokenized = word_tokenize(sentence)\n",
    "        for word in sentence_tokenized:\n",
    "            if word not in vocab:\n",
    "                vocab.append(word)\n",
    "\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ir2tH1d4cdyg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ir2tH1d4cdyg",
    "outputId": "2e89e598-2c28-4034-8d16-0c66c0810104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 10660 token in english_vocab\n"
     ]
    }
   ],
   "source": [
    "#english_vocab = build_vocab(input_texts)\n",
    "english_vocab = build_vocab(train_inputs)\n",
    "print(f\"There is {len(english_vocab)} token in english_vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gk8nsa2wbRV8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gk8nsa2wbRV8",
    "outputId": "685bcd5c-7ad6-4756-8e9c-13a197aa0908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 17498 token in french_vocab\n"
     ]
    }
   ],
   "source": [
    "#french_vocab = build_vocab(target_texts)\n",
    "french_vocab = build_vocab(train_targets)\n",
    "print(f\"There is {len(french_vocab)} token in french_vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g9C8b0ZJdsg0",
   "metadata": {
    "id": "g9C8b0ZJdsg0"
   },
   "outputs": [],
   "source": [
    "english_vocab = [pad, unk, bos, eos] + english_vocab\n",
    "french_vocab = [pad, unk, bos, eos] + french_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FI5sj78zeQSA",
   "metadata": {
    "id": "FI5sj78zeQSA"
   },
   "outputs": [],
   "source": [
    "word2idx_eng = {}\n",
    "for i in range(len(english_vocab)):\n",
    "    word2idx_eng[english_vocab[i]] = i\n",
    "\n",
    "word2idx_fr = {}\n",
    "for i in range(len(french_vocab)):\n",
    "    word2idx_fr[french_vocab[i]] = i\n",
    "\n",
    "# map indexes back into real words\n",
    "# so wwe can view the results\n",
    "idx2word_eng = {v: w for w, v in word2idx_eng.items()}\n",
    "idx2word_trans = {v: w for w, v in word2idx_fr.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y1DqnJrH1ibf",
   "metadata": {
    "id": "y1DqnJrH1ibf"
   },
   "source": [
    "# Build Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WKaLfpoAIHCm",
   "metadata": {
    "id": "WKaLfpoAIHCm"
   },
   "outputs": [],
   "source": [
    "def build_sequences(texts, word2idx):\n",
    "    sequences = []\n",
    "    for sentence in texts:\n",
    "        sequence = []\n",
    "        sentence_tokenized = word_tokenize(sentence)\n",
    "        for token in sentence_tokenized:\n",
    "            if token in word2idx.keys():\n",
    "                sequence.append(word2idx[token])\n",
    "            else:\n",
    "                sequence.append(word2idx[unk])\n",
    "        sequences.append(sequence)\n",
    "    return sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PrtuIW5lIfWc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PrtuIW5lIfWc",
    "outputId": "27e813c5-cb0a-423c-9e0b-9029805d7ed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(input_sequences_train): 120000\n",
      "len(input_sequences_test): 30000\n"
     ]
    }
   ],
   "source": [
    "# input_sequences = build_sequences(input_texts, word2idx_eng)\n",
    "# target_sequences = build_sequences(target_texts, word2idx_fr)\n",
    "\n",
    "input_sequences_train = build_sequences(train_inputs, word2idx_eng)\n",
    "target_sequences_train = build_sequences(train_targets, word2idx_fr)\n",
    "\n",
    "input_sequences_test = build_sequences(test_inputs, word2idx_eng)\n",
    "target_sequences_test = build_sequences(test_targets, word2idx_fr)\n",
    "\n",
    "print(\"len(input_sequences_train):\", len(input_sequences_train))\n",
    "print(\"len(input_sequences_test):\", len(input_sequences_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qcCgTJ4XQNL2",
   "metadata": {
    "id": "qcCgTJ4XQNL2"
   },
   "outputs": [],
   "source": [
    "bos_idx = word2idx_eng[bos]\n",
    "eos_idx = word2idx_eng[eos]\n",
    "\n",
    "# target_sequences_inputs = [[bos_idx] + sequence for sequence in target_sequences]\n",
    "# target_sequences = [sequence + [eos_idx] for sequence in target_sequences]\n",
    "\n",
    "target_sequences_train_inputs = [[bos_idx] + sequence for sequence in target_sequences_train]\n",
    "target_sequences_train = [sequence + [eos_idx] for sequence in target_sequences_train]\n",
    "\n",
    "target_sequences_test_inputs = [[bos_idx] + sequence for sequence in target_sequences_test]\n",
    "target_sequences_test = [sequence + [eos_idx] for sequence in target_sequences_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UeNRl2reHUgN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UeNRl2reHUgN",
    "outputId": "c8a4e50a-fa58-4810-8040-dde14f19f597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len_input: 13\n"
     ]
    }
   ],
   "source": [
    "#max_len_input = max(len(s) for s in input_sequences)\n",
    "max_len_input = max(len(s) for s in input_sequences_train)\n",
    "\n",
    "print(\"max_len_input:\", max_len_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XePVcEVsJCDr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XePVcEVsJCDr",
    "outputId": "bbbab58d-00cd-42bd-8b2c-18eda309d9a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len_target: 20\n"
     ]
    }
   ],
   "source": [
    "max_len_target = max(len(s) for s in target_sequences_train)\n",
    "#max_len_target = max(len(s) for s in target_sequences)\n",
    "\n",
    "print(\"max_len_target:\", max_len_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KzYZeMs21k7s",
   "metadata": {
    "id": "KzYZeMs21k7s"
   },
   "source": [
    "# Dataset Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79Mgy6AKMXCQ",
   "metadata": {
    "id": "79Mgy6AKMXCQ"
   },
   "outputs": [],
   "source": [
    "# build data set\n",
    "class Translation(data.Dataset):\n",
    "    def __init__(self, max_len_input, max_len_target,input_sequences, target_sequences, target_sequences_inputs):\n",
    "        self.max_len_input = max_len_input\n",
    "        self.max_len_target = max_len_target\n",
    "        self.input_sequences = input_sequences\n",
    "        self.target_sequences = target_sequences\n",
    "        self.target_sequences_inputs = target_sequences_inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_sequences )\n",
    "\n",
    "    def pad_input(self, sequence):\n",
    "        max_len = self.max_len_input\n",
    "        sequence_len = len(sequence)\n",
    "        if sequence_len >= max_len:\n",
    "            sequence = sequence[:max_len]\n",
    "        else:\n",
    "            sequence = [0] * (max_len - sequence_len) + sequence\n",
    "        \n",
    "        return sequence\n",
    "\n",
    "    def pad_target(self, sequence):\n",
    "        max_len = self.max_len_target\n",
    "        sequence_len = len(sequence)\n",
    "        if sequence_len >= max_len:\n",
    "            sequence = sequence[:max_len]\n",
    "        else:\n",
    "            sequence = sequence + [0] * (max_len - sequence_len)  \n",
    "        return sequence\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        encoder_in = self.pad_input(self.input_sequences[idx])\n",
    "        decoder_in = self.pad_target(self.target_sequences_inputs[idx])\n",
    "        decoder_out = self.pad_target(self.target_sequences[idx])\n",
    "\n",
    "        encoder_in = torch.LongTensor(encoder_in)\n",
    "        decoder_in = torch.LongTensor(decoder_in)\n",
    "        decoder_out = torch.FloatTensor(decoder_out)\n",
    "\n",
    "    \n",
    "        return encoder_in, decoder_in, decoder_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gN9t2TcV1ocX",
   "metadata": {
    "id": "gN9t2TcV1ocX"
   },
   "source": [
    "# Load Pre-trained embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Krj-x_AL9EtW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Krj-x_AL9EtW",
    "outputId": "df6fe8a7-0625-44bd-b22c-77fea6ff832e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-30 11:29:31--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2022-04-30 11:29:31--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2022-04-30 11:29:31--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.06MB/s    in 2m 40s  \n",
      "\n",
      "2022-04-30 11:32:11 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -qq glove.6B.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f883a42",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f883a42",
    "outputId": "4425fa1d-715e-4777-9b13-5ded8a24310f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word vectors ...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load in pre-trained word vectors\n",
    "print(\"loading word vectors ...\")\n",
    "word2vec_path = 'glove.6B.%sd.txt'\n",
    "word2vec = {}\n",
    "with open(\n",
    "    os.path.join(word2vec_path % EMBEDDING_DIM)\n",
    ") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.array(values[1:], dtype=\"float32\")\n",
    "        word2vec[word] = vec\n",
    "    print(\"Found %s word vectors.\" % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b1ede",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "909b1ede",
    "outputId": "f503d479-8bf3-40e4-9547-0530d4314ce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print(\"Filling pre-trained embeddings...\")\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_eng))\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_eng.items():\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all zeros\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YZFPlAWc1x-z",
   "metadata": {
    "id": "YZFPlAWc1x-z"
   },
   "source": [
    "# Dataset Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00baa7c",
   "metadata": {
    "id": "b00baa7c"
   },
   "outputs": [],
   "source": [
    "# instantiate dataset\n",
    "#translation_dataset = Translation(max_len_input, max_len_target, input_sequences, target_sequences, target_sequences_inputs)\n",
    "train_dataset = Translation(max_len_input, max_len_target, input_sequences_train, target_sequences_train, target_sequences_train_inputs)\n",
    "test_dataset = Translation(max_len_input, max_len_target, input_sequences_test, target_sequences_test, target_sequences_test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911971a7",
   "metadata": {
    "id": "911971a7"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f5aad",
   "metadata": {
    "id": "386f5aad"
   },
   "outputs": [],
   "source": [
    "# load pre-trained word embeddings into an embedding layer\n",
    "# freeze the layer\n",
    "embedding_layer = nn.Embedding(num_words, EMBEDDING_DIM)  # vocab size  # embedding dim\n",
    "embedding_layer.weight = nn.Parameter(torch.from_numpy(embedding_matrix).float())\n",
    "embedding_layer.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4q9oEaqc12F2",
   "metadata": {
    "id": "4q9oEaqc12F2"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de69bbe7",
   "metadata": {
    "id": "de69bbe7"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size,embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size # LATENT_DIM\n",
    "        self.num_layers = num_layers # 1 or 2\n",
    "\n",
    "        self.embedding = embedding_layer # vocab size x EMBEDDING_DIM\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True) # -> T x N x 2*hidden\n",
    "\n",
    "        self.fc_hidden = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.fc_cell = nn.Linear(hidden_size*2, hidden_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (N, T encoder) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x)) # (T encoder, N, EMBEDDING_DIM)\n",
    "        # embedding shape: # (T encoder, N, EMBEDDING_DIM)\n",
    "\n",
    "        encoder_states, (hidden, cell) = self.rnn(embedding)\n",
    "        #  encoder_states shape:  (T encoder *num_layers , N, 2*hidden_size) \n",
    "        # hidden, cell : (2*num_layers, N, hidden_size) bidirectional = True\n",
    "        \n",
    "        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "        # now : hidden, cell : (num_layers, N, hidden_size) \n",
    "        \n",
    "        return encoder_states, hidden, cell\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42daaf60",
   "metadata": {
    "id": "42daaf60"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size # LATENT_DIM\n",
    "        self.num_layers = num_layers  # 1 or 2\n",
    " \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size) # input size = vocab fr size = num_words_output\n",
    "        self.rnn = nn.LSTM(hidden_size*2 + embedding_size, hidden_size, num_layers)\n",
    "        # -> T decoder x N x hidden\n",
    "       \n",
    "        self.energy = nn.Linear(hidden_size*3,1)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_size, output_size) # ->  T x N x output size\n",
    "        \n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        # x shape: (N) where N is for batch size, we want it to be (N, 1), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        x = x.unsqueeze(0) # -> (1, N)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        sequence_length = encoder_states.shape[0] # T_encoder\n",
    "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
    "        # (T * num_layers, N, hidden_size)\n",
    "            \n",
    "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
    "        # -> (T, N, 1)\n",
    "        attention = self.softmax(energy) \n",
    "        #(T, N, 1)\n",
    "        attention = attention.permute(1,2,0)\n",
    "        #(N, 1, T)\n",
    "        encoder_states = encoder_states.permute(1,0,2)\n",
    "        #(N, T, 2*hidden)\n",
    "            \n",
    "        context_vector = torch.bmm(attention, encoder_states).permute(1,0,2)\n",
    "        # (N, 1, 2*hidden) -> (1, N, 2*hidden)\n",
    "        \n",
    "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
    "        # rnn_input: (1, N, hidden_size*2 + embedding_size)\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        # (1, N, 2*hidden + embedding_size) ->(1, N,  hidden)\n",
    "        # outputs shape: (1, N,  hidden)\n",
    "        # hidden, cell: (1, N,  hidden)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "        # -> (1, N, output_size)\n",
    "\n",
    "        # predictions shape: (N, 1, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) s\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c131bc",
   "metadata": {
    "id": "a1c131bc"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, teacher_force_ratio=1):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.teacher_force_ratio = teacher_force_ratio\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        # source = encoder_inputs\n",
    "        # target = encoder_inputs\n",
    "        batch_size = source.shape[1] # source (T_encoder, N)\n",
    "        target_len = target.shape[0] # target (T_decoder, N)\n",
    "        target_vocab_size = len(word2idx_fr) # check this is correct num_words = len(word2idx_outputs) + 1 \n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device) # (T_decoder, N, vocab)\n",
    "\n",
    "        encoder_states, hidden, cell = self.encoder(source) # (num_layers, N, hidden_size) \n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0] # (1, N)\n",
    "        outputs[-1] = word2idx_fr[eos] * torch.ones(batch_size, target_vocab_size).to(device)\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            #hidden, cell = hidden.squeeze(1), cell.squeeze(1)\n",
    "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[t-1] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            x = target[t] if random.random() < self.teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wscQnOy32CZs",
   "metadata": {
    "id": "wscQnOy32CZs"
   },
   "source": [
    "# Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53741ff1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53741ff1",
    "outputId": "87d1efee-d69c-4559-d97c-feacd1ffe240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"device:\", device)\n",
    "input_size_encoder = len(word2idx_eng)\n",
    "input_size_decoder = len(word2idx_fr)\n",
    "output_size = len(word2idx_fr)\n",
    "encoder_embedding_size = EMBEDDING_DIM\n",
    "decoder_embedding_size = EMBEDDING_DIM\n",
    "hidden_size = LATENT_DIM  \n",
    "num_layers = 1\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 300\n",
    "learning_rate = 0.001\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee8a8b2",
   "metadata": {
    "id": "eee8a8b2"
   },
   "outputs": [],
   "source": [
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb0e2d8",
   "metadata": {
    "id": "eeb0e2d8"
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoder_net, decoder_net).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049655b-7944-4832-bdc6-51bdc5090fe1",
   "metadata": {
    "id": "d049655b-7944-4832-bdc6-51bdc5090fe1"
   },
   "outputs": [],
   "source": [
    "#model = torch.load('./translation_attention.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ddda6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75ddda6f",
    "outputId": "8d5fb0da-43d0-4df9-af4e-4824c94bca7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(10664, 100)\n",
       "    (rnn): LSTM(100, 256, bidirectional=True)\n",
       "    (fc_hidden): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (fc_cell): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(17502, 100)\n",
       "    (rnn): LSTM(612, 256)\n",
       "    (energy): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (softmax): Softmax(dim=0)\n",
       "    (relu): ReLU()\n",
       "    (fc): Linear(in_features=256, out_features=17502, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss and optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)#, weight_decay=1e-3)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4k58V7sN2K5g",
   "metadata": {
    "id": "4k58V7sN2K5g"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3323154a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3323154a",
    "outputId": "c4382671-7a4d-40cd-a10a-1eb34b2a53b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 / 40]\n",
      "Train Loss: 1.711, Test Loss: 1.450\n",
      "[Epoch 2 / 40]\n",
      "Train Loss: 1.333, Test Loss: 1.239\n",
      "[Epoch 3 / 40]\n",
      "Train Loss: 1.266, Test Loss: 1.125\n",
      "[Epoch 4 / 40]\n",
      "Train Loss: 1.167, Test Loss: 1.048\n",
      "[Epoch 5 / 40]\n",
      "Train Loss: 1.110, Test Loss: 1.011\n",
      "[Epoch 6 / 40]\n",
      "Train Loss: 0.943, Test Loss: 0.967\n",
      "[Epoch 7 / 40]\n",
      "Train Loss: 0.960, Test Loss: 0.966\n",
      "[Epoch 8 / 40]\n",
      "Train Loss: 0.929, Test Loss: 0.942\n",
      "[Epoch 9 / 40]\n",
      "Train Loss: 0.895, Test Loss: 0.936\n",
      "[Epoch 10 / 40]\n",
      "Train Loss: 0.881, Test Loss: 0.925\n",
      "[Epoch 11 / 40]\n",
      "Train Loss: 0.886, Test Loss: 0.926\n",
      "[Epoch 12 / 40]\n",
      "Train Loss: 0.836, Test Loss: 0.923\n",
      "[Epoch 13 / 40]\n",
      "Train Loss: 0.832, Test Loss: 0.902\n",
      "[Epoch 14 / 40]\n",
      "Train Loss: 0.864, Test Loss: 0.908\n",
      "[Epoch 15 / 40]\n",
      "Train Loss: 0.841, Test Loss: 0.916\n",
      "[Epoch 16 / 40]\n",
      "Train Loss: 0.830, Test Loss: 0.898\n",
      "[Epoch 17 / 40]\n",
      "Train Loss: 0.804, Test Loss: 0.901\n",
      "[Epoch 18 / 40]\n",
      "Train Loss: 0.772, Test Loss: 0.901\n",
      "[Epoch 19 / 40]\n",
      "Train Loss: 0.795, Test Loss: 0.888\n",
      "[Epoch 20 / 40]\n",
      "Train Loss: 0.747, Test Loss: 0.909\n",
      "[Epoch 21 / 40]\n",
      "Train Loss: 0.777, Test Loss: 0.906\n",
      "[Epoch 22 / 40]\n",
      "Train Loss: 0.751, Test Loss: 0.898\n",
      "[Epoch 23 / 40]\n",
      "Train Loss: 0.768, Test Loss: 0.928\n",
      "[Epoch 24 / 40]\n",
      "Train Loss: 0.706, Test Loss: 0.912\n",
      "[Epoch 25 / 40]\n",
      "Train Loss: 0.739, Test Loss: 0.912\n",
      "[Epoch 26 / 40]\n",
      "Train Loss: 0.752, Test Loss: 0.913\n",
      "[Epoch 27 / 40]\n",
      "Train Loss: 0.741, Test Loss: 0.903\n",
      "[Epoch 28 / 40]\n",
      "Train Loss: 0.761, Test Loss: 0.907\n",
      "[Epoch 29 / 40]\n",
      "Train Loss: 0.785, Test Loss: 0.921\n",
      "[Epoch 30 / 40]\n",
      "Train Loss: 0.771, Test Loss: 0.939\n",
      "[Epoch 31 / 40]\n",
      "Train Loss: 0.724, Test Loss: 0.930\n",
      "[Epoch 32 / 40]\n",
      "Train Loss: 0.773, Test Loss: 0.921\n",
      "[Epoch 33 / 40]\n",
      "Train Loss: 0.713, Test Loss: 0.929\n",
      "[Epoch 34 / 40]\n",
      "Train Loss: 0.702, Test Loss: 0.936\n",
      "[Epoch 35 / 40]\n",
      "Train Loss: 0.749, Test Loss: 0.904\n",
      "[Epoch 36 / 40]\n",
      "Train Loss: 0.732, Test Loss: 0.923\n",
      "[Epoch 37 / 40]\n",
      "Train Loss: 0.668, Test Loss: 0.920\n",
      "[Epoch 38 / 40]\n",
      "Train Loss: 0.741, Test Loss: 0.906\n",
      "[Epoch 39 / 40]\n",
      "Train Loss: 0.670, Test Loss: 0.936\n",
      "[Epoch 40 / 40]\n",
      "Train Loss: 0.676, Test Loss: 0.935\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "\n",
    "train_losses = np.zeros(num_epochs)\n",
    "test_losses = np.zeros(num_epochs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch+1} / {num_epochs}]\")\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        train_loss = []\n",
    "        # Get input and targets and get to cuda\n",
    "        # encoder_in, decoder_in, decoder_out\n",
    "        encoder_in, decoder_in, target = batch\n",
    "        encoder_in, decoder_in, target = encoder_in.to(device), decoder_in.to(device), target.to(device)\n",
    "        encoder_in, decoder_in, target = encoder_in.permute(1,0), decoder_in.permute(1,0), target.permute(1,0)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(encoder_in, decoder_in)\n",
    "\n",
    "        \n",
    "        # reshape output/target for loss function\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target.reshape(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target.long())\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient clip trick\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        test_loss = []\n",
    "        # Get input and targets and get to cuda\n",
    "        # encoder_in, decoder_in, decoder_out\n",
    "        encoder_in, decoder_in, target = batch\n",
    "        encoder_in, decoder_in, target = encoder_in.to(device), decoder_in.to(device), target.to(device)\n",
    "        encoder_in, decoder_in, target = encoder_in.permute(1,0), decoder_in.permute(1,0), target.permute(1,0)\n",
    "  \n",
    "        # Forward prop\n",
    "        output = model(encoder_in, decoder_in)\n",
    "\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target.reshape(-1)\n",
    "        loss = criterion(output, target.long())\n",
    "        test_loss.append(loss.item())\n",
    "    \n",
    "    epoch_train_loss = np.mean(train_loss)           \n",
    "    train_losses[epoch] = epoch_train_loss\n",
    "\n",
    "    epoch_test_loss = np.mean(test_loss)           \n",
    "    test_losses[epoch] = epoch_test_loss\n",
    "\n",
    "    print(f'Train Loss: {epoch_train_loss:.3f}, Test Loss: {epoch_test_loss:.3f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OhLO_0SC2Tt1",
   "metadata": {
    "id": "OhLO_0SC2Tt1"
   },
   "source": [
    "# Loss and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280fd65-c6bd-4fa0-adf1-96c4ffaa1efe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "2280fd65-c6bd-4fa0-adf1-96c4ffaa1efe",
    "outputId": "4bd6eeaa-de15-4a69-ab47-b47b135570a4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# some plots\n",
    "plt.plot(train_losses, label=\"train_loss\")\n",
    "plt.plot(test_losses, label=\"test_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc144df",
   "metadata": {
    "id": "0bc144df"
   },
   "outputs": [],
   "source": [
    "torch.save(model, os.path.join(translation_path, f\"translation_attention_{NUM_SAMPLES}.pth\"))\n",
    "#torch.save(model, os.path.join(translation_path, \"translation_attention_train_test.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xAmlGEVSU0CJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xAmlGEVSU0CJ",
    "outputId": "f54229e1-881b-4e3c-94a8-91ed353c1e3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(10664, 100)\n",
       "    (rnn): LSTM(100, 256, bidirectional=True)\n",
       "    (fc_hidden): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (fc_cell): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(17502, 100)\n",
       "    (rnn): LSTM(612, 256)\n",
       "    (energy): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (softmax): Softmax(dim=0)\n",
       "    (relu): ReLU()\n",
       "    (fc): Linear(in_features=256, out_features=17502, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52db17d-e806-41cf-99a2-dca07f1ae166",
   "metadata": {
    "id": "f52db17d-e806-41cf-99a2-dca07f1ae166"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # encode the input as state vectors.\n",
    "    input_seq = input_seq.to(device)\n",
    "    with torch.no_grad():\n",
    "        encoder_states, h, c = encoder_net(input_seq)\n",
    "\n",
    "        # generate empty target seq of length 1\n",
    "        target_seq = torch.zeros(1).int().to(device)\n",
    "\n",
    "        # populate the first character of target sequence with the start character\n",
    "        target_seq[0] = word2idx_fr[bos]\n",
    "\n",
    "        # if we get this we break\n",
    "        eos_idx = word2idx_fr[eos]\n",
    "\n",
    "        # create translation\n",
    "        output_sentence = []\n",
    "        for _ in range(max_len_target):\n",
    "            output_tokens, h, c = decoder_net(target_seq, encoder_states, h, c)\n",
    "\n",
    "            # get next word\n",
    "            idx = output_tokens.argmax(1).item()\n",
    "\n",
    "            # end of sentence EOS\n",
    "            if eos_idx == idx:\n",
    "                break\n",
    "\n",
    "            word = \"\"\n",
    "            if idx > 0:\n",
    "                word = idx2word_trans[idx]\n",
    "                output_sentence.append(word)\n",
    "\n",
    "            # update the decoder input\n",
    "            # which is just the word just generated\n",
    "            target_seq[0] = idx\n",
    "\n",
    "        return \" \".join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ID_BNpCsiGCV",
   "metadata": {
    "id": "ID_BNpCsiGCV"
   },
   "outputs": [],
   "source": [
    "#from nltk.translate import bleu\n",
    "import nltk.translate.bleu_score as bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HTBsSJDI2kzs",
   "metadata": {
    "id": "HTBsSJDI2kzs"
   },
   "source": [
    "### Translation for train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55bba23-35e4-4eb0-a2d4-57c388d17104",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d55bba23-35e4-4eb0-a2d4-57c388d17104",
    "outputId": "78bbbb9d-0c00-4d6e-d3b6-4338d3c3e93d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: soldiers are used to danger .\n",
      "True Translation: les soldats sont habitues au danger .\n",
      "Predicted Translation: les soldats sont habitues au danger .\n",
      "BLEU Score 1.0\n",
      "Continue? [Y/n]y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: where is my newspaper ?\n",
      "True Translation: ou se trouve mon journal ?\n",
      "Predicted Translation: ou est mon journal ?\n",
      "BLEU Score 0.5081327481546147\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: i was worried for nothing .\n",
      "True Translation: je me suis fait du souci pour rien .\n",
      "Predicted Translation: je me fis du souci pour rien .\n",
      "BLEU Score 0.5133450480401704\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: it s not our job to do that .\n",
      "True Translation: ce n est pas notre travail de faire cela .\n",
      "Predicted Translation: ce n est pas notre travail de faire cela .\n",
      "BLEU Score 1.0\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: whose notebook is that ?\n",
      "True Translation: de qui est ce le laptop ?\n",
      "Predicted Translation: a qui est ce cahier ?\n",
      "BLEU Score 0.4417918226831577\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: tom is opening the box .\n",
      "True Translation: tom ouvre la boite .\n",
      "Predicted Translation: tom ouvre la boite .\n",
      "BLEU Score 1.0\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: don t tell anybody .\n",
      "True Translation: ne le dis a personne !\n",
      "Predicted Translation: ne le dis a personne !\n",
      "BLEU Score 1.0\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: why is your dog limping ?\n",
      "True Translation: pourquoi ton chien boite t il ?\n",
      "Predicted Translation: pourquoi ton chien est il en train de haleter ?\n",
      "BLEU Score 0.3043119239482219\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: i don t feel like exercising .\n",
      "True Translation: je n ai pas envie de faire de l exercice .\n",
      "Predicted Translation: je n ai pas envie de faire du progres .\n",
      "BLEU Score 0.5900468726392808\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: get down from there .\n",
      "True Translation: descends de la !\n",
      "Predicted Translation: descends de la !\n",
      "BLEU Score 1.0\n",
      "Continue? [Y/n]y\n",
      "_\n",
      "Input: seven minus two is five .\n",
      "True Translation: sept moins deux egal cinq .\n",
      "Predicted Translation: sept sept sept egal cinq .\n",
      "BLEU Score 0.5081327481546147\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # do some translation for training data\n",
    "    i = np.random.choice(len(train_inputs))\n",
    "    #input_seq = encoder_inputs[i : i + 1]\n",
    "    input_seq, _, _ = train_dataset[i]\n",
    "    input_seq = input_seq.unsqueeze(1)\n",
    "    #input_seq = torch.from_numpy(input_seq).to(device).permute(1,0)\n",
    "    translation = decode_sequence(input_seq)\n",
    "    print(\"_\")\n",
    "    print(\"Input:\", train_inputs[i])\n",
    "    print(\"True Translation:\", train_targets[i])\n",
    "    print(\"Predicted Translation:\", translation)\n",
    "    pred_translation = word_tokenize(translation)\n",
    "    true_translation = word_tokenize(train_targets[i])\n",
    "    if len(translation) > 0:\n",
    "        print(\"BLEU Score\", bleu.sentence_bleu([pred_translation], true_translation))#, smoothing_function=smoothie))\n",
    "\n",
    "    ans = input(\"Continue? [Y/n]\")\n",
    "    if ans and ans.lower().startswith(\"n\"):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mw4b1iwn2oec",
   "metadata": {
    "id": "mw4b1iwn2oec"
   },
   "source": [
    "### Translation for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HJ7LZmZLNpzU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJ7LZmZLNpzU",
    "outputId": "0b6910c7-7415-42c8-9711-99d56000ef48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: no one wants to look like a fool .\n",
      "True Translation: personne ne veut passer pour un idiot .\n",
      "Predicted Translation: personne ne veut voir un idiot .\n",
      "BLEU Score 0.6147881529512643\n",
      "Continue? [Y/n]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: be quiet or the baby will wake up .\n",
      "True Translation: reste calme sinon le bebe va se reveiller .\n",
      "Predicted Translation: soyez calme le bebe le bebe se coucher du bebe .\n",
      "BLEU Score 0.41105458056789007\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: the car has a new engine .\n",
      "True Translation: la voiture est equipee d un nouveau moteur .\n",
      "Predicted Translation: la voiture a un nouveau volant .\n",
      "BLEU Score 0.6104735835807844\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: he drank beer .\n",
      "True Translation: il a bu de la biere .\n",
      "Predicted Translation: il but de la biere .\n",
      "BLEU Score 0.4347208719449914\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: i wish it would happen more often .\n",
      "True Translation: j aimerais que ca se produise plus souvent .\n",
      "Predicted Translation: j aimerais que ca arrive souvent plus souvent .\n",
      "BLEU Score 0.43167001068522526\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: i don t know who you are .\n",
      "True Translation: j ignore qui vous etes .\n",
      "Predicted Translation: je ne sais pas qui vous etes .\n",
      "BLEU Score 0.36409302398068727\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: don t let go of the rope .\n",
      "True Translation: ne lache pas la corde .\n",
      "Predicted Translation: ne lache pas de corde !\n",
      "BLEU Score 0.5081327481546147\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: i ve done that many times .\n",
      "True Translation: j ai fait ca de nombreuses fois .\n",
      "Predicted Translation: j ai fait ca beaucoup de fois .\n",
      "BLEU Score 0.42728700639623407\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: we just want you to think about it .\n",
      "True Translation: nous voulons juste que tu y penses .\n",
      "Predicted Translation: il se simplement juste que tu y reflechisses .\n",
      "BLEU Score 0.32260135189272865\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # do some translation for testing data\n",
    "    i = np.random.choice(len(test_inputs))\n",
    "    #input_seq = encoder_inputs[i : i + 1]\n",
    "    input_seq, _, _ = test_dataset[i]\n",
    "    input_seq = input_seq.unsqueeze(1)\n",
    "    #input_seq = torch.from_numpy(input_seq).to(device).permute(1,0)\n",
    "    translation = decode_sequence(input_seq)\n",
    "    print(\"_\")\n",
    "    print(\"Input:\", test_inputs[i])\n",
    "    print(\"True Translation:\", test_targets[i])\n",
    "    print(\"Predicted Translation:\", translation)\n",
    "    pred_translation = word_tokenize(translation)\n",
    "    true_translation = word_tokenize(test_targets[i])\n",
    "    if len(translation) > 0:\n",
    "        print(\"BLEU Score\", bleu.sentence_bleu([pred_translation], true_translation))#, smoothing_function=smoothie))\n",
    "\n",
    "    ans = input(\"Continue? [Y/n]\")\n",
    "    if ans and ans.lower().startswith(\"n\"):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mRPds-SO2rsh",
   "metadata": {
    "id": "mRPds-SO2rsh"
   },
   "source": [
    "### BLEU scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xVZsDb5TisTi",
   "metadata": {
    "id": "xVZsDb5TisTi"
   },
   "outputs": [],
   "source": [
    "def evaluate(input_texts, target_texts, translation_dataset, mode=\"train\"):\n",
    "    score = 0\n",
    "    for i in range(len(input_texts)):\n",
    "        input_seq, _, _ = translation_dataset[i]\n",
    "        input_seq = input_seq.unsqueeze(1)\n",
    "        #input_seq = torch.from_numpy(input_seq).to(device).permute(1,0)\n",
    "        translation = decode_sequence(input_seq)\n",
    "        pred_translation = word_tokenize(translation)\n",
    "        true_translation = word_tokenize(target_texts[i])\n",
    "        if len(translation) > 0:\n",
    "            score += bleu.sentence_bleu([pred_translation], true_translation)#, smoothing_function=smoothie))\n",
    "\n",
    "    score = 100 * score / len(input_texts)\n",
    "    print(\"BLEU score on\" + mode + \" set:\", score)\n",
    "    return score \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZgqvjEpYCA2-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgqvjEpYCA2-",
    "outputId": "274618ab-b4ad-4594-b9f8-4f6eb407825a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score ontrain set: 75.79947836708762\n",
      "BLEU score ontest set: 61.62797747223698\n"
     ]
    }
   ],
   "source": [
    "# evaluation train_data\n",
    "train_score = evaluate(train_inputs, train_targets, train_dataset)\n",
    "\n",
    "# evaluation test_data\n",
    "test_score = evaluate(test_inputs, test_targets, test_dataset, mode=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QXmqpvOI2wuw",
   "metadata": {
    "id": "QXmqpvOI2wuw"
   },
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YSrt1SfcL0Jl",
   "metadata": {
    "id": "YSrt1SfcL0Jl"
   },
   "outputs": [],
   "source": [
    "# plt.switch_backend('agg')\n",
    "# import matplotlib.ticker as ticker\n",
    "\n",
    "# def showAttention(input_sentence, output_words, attentions):\n",
    "#     # Set up figure with colorbar\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "#     fig.colorbar(cax)\n",
    "\n",
    "#     # Set up axes\n",
    "#     ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "#                        ['<EOS>'], rotation=90)\n",
    "#     ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "#     # Show label at every tick\n",
    "#     ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "#     ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "name": "nltk translation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
