{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b27e24ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df92808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some configuration\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20_000\n",
    "NUM_SAMPLES = 50_000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02f4be06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 50000\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "input_texts = []  # sentence in original language\n",
    "target_texts = []  # sentence in target language\n",
    "target_text_inputs = []  #  sentence in target language offset by 1\n",
    "t = 0\n",
    "for line in open(\"./fra.txt\"):\n",
    "    # only keep a limited number of samples\n",
    "    t += 1\n",
    "    if t > NUM_SAMPLES:\n",
    "        break\n",
    "    line = line.rstrip()\n",
    "    # input and targets are separeted by tab\n",
    "    if \"\\t\" not in line:\n",
    "        continue\n",
    "\n",
    "    # split up the input and translation\n",
    "    input_text, translation = line.split(\"\\t\")[:2]\n",
    "\n",
    "    # make the target input and output\n",
    "    # recall we'll be using teacher forcing\n",
    "    target_text = translation + \" <eos>\"\n",
    "    target_text_input = \"<sos> \" + translation\n",
    "\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    target_text_inputs.append(target_text_input)\n",
    "print(\"num samples:\", len(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4651a080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6090 unique input tokens\n"
     ]
    }
   ],
   "source": [
    "#  tokenize inputs\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "\n",
    "\n",
    "# get word -> integer mapping\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print(\"Found %s unique input tokens\" % len(word2idx_inputs))\n",
    "\n",
    "# determine maximum length input sequence\n",
    "max_len_input = max(len(s) for s in input_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85d74c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17859 unique output tokens\n"
     ]
    }
   ],
   "source": [
    "# tokenize outputs\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters=\"\")\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_text_inputs)\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_text_inputs)\n",
    "\n",
    "# get word -> integer mapping for outputs\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print(\"Found %s unique output tokens\" % len(word2idx_outputs))\n",
    "\n",
    "\n",
    "# store number of output wors for later\n",
    "# remember to add 1 since indexing start at 1\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "\n",
    "# determine maximum length output sequence\n",
    "max_len_target = max(len(s) for s in target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf0a3720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_data.shape: (50000, 7)\n",
      "encoder_data[0]: [ 0  0  0  0  0  0 25]\n",
      "decoder_data.shape: (50000, 15)\n",
      "decoder_data[0]: [ 2 82 13  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_data.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_data[0]:\", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(\n",
    "    target_sequences_inputs, maxlen=max_len_target, padding=\"post\"\n",
    ")\n",
    "print(\"decoder_data.shape:\", decoder_inputs.shape)\n",
    "print(\"decoder_data[0]:\", decoder_inputs[0])\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f883a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word vectors ...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load in pre-trained word vectors\n",
    "print(\"loading word vectors ...\")\n",
    "word2vec_path = '../Lazyprogrammer/large_files/glove.6B/glove.6B.%sd.txt'\n",
    "word2vec = {}\n",
    "with open(\n",
    "    os.path.join(word2vec_path % EMBEDDING_DIM)\n",
    ") as f:\n",
    "    # is just a space-separated text file in the format:\n",
    "    # word vec[0] vec[1] vec[2]\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.array(values[1:], dtype=\"float32\")\n",
    "        word2vec[word] = vec\n",
    "    print(\"Found %s word vectors.\" % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "909b1ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print(\"Filling pre-trained embeddings...\")\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i < MAX_NUM_WORDS:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all zeros\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e89dbdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot the targets (can't use sparse categorical cross entropy)\n",
    "decoder_targets_one_hot = np.zeros(\n",
    "    (len(input_sequences), max_len_target, num_words_output), dtype=\"float32\"\n",
    ")\n",
    "for i, d in enumerate(decoder_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91f26677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data set\n",
    "class Translation(data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.encoder_in = torch.from_numpy(encoder_inputs).int()\n",
    "        self.decoder_in = torch.from_numpy(decoder_inputs).int()\n",
    "        self.decoder_out = torch.from_numpy(decoder_targets).float()\n",
    "        #self.decoder_out = torch.from_numpy(decoder_targets_one_hot).float()\n",
    "    def __len__(self):\n",
    "        return len(encoder_inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        encoder_in = self.encoder_in[idx]\n",
    "        decoder_in = self.decoder_in[idx]\n",
    "        decoder_out = self.decoder_out[idx]\n",
    "        \n",
    "    \n",
    "        return encoder_in, decoder_in, decoder_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b00baa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate dataset\n",
    "translation_dataset = Translation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "911971a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=translation_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f23532f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 7]) torch.Size([64, 15]) torch.Size([64, 15])\n"
     ]
    }
   ],
   "source": [
    "for inputs, inputs_d, targets in data_loader:\n",
    "    print(inputs.shape, inputs_d.shape, targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "386f5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word embeddings into an embedding layer\n",
    "# freeze the layer\n",
    "embedding_layer = nn.Embedding(num_words, EMBEDDING_DIM)  # vocab size  # embedding dim\n",
    "embedding_layer.weight = nn.Parameter(torch.from_numpy(embedding_matrix).float())\n",
    "embedding_layer.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de69bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some configuration\n",
    "# EMBEDDING_DIM = 100\n",
    "# LATENT_DIM = 256\n",
    "# T encoder = 4\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size,embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size # LATENT_DIM\n",
    "        self.num_layers = num_layers # 1 or 2\n",
    "\n",
    "        self.embedding = embedding_layer # vocab size x EMBEDDING_DIM\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p, batch_first=True) # -> N x T x hidden\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (N, T encoder) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x)) # (N, T encoder, EMBEDDING_DIM)\n",
    "        # embedding shape: # (N, T encoder, EMBEDDING_DIM)\n",
    "\n",
    "        _ , (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "        #  outputs shape:  (N, T encoder , hidden_size) \n",
    "        # hidden, cell : (num_layers, hidden_size)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42daaf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_DIM = 100\n",
    "# LATENT_DIM = 256\n",
    "# T decoder = 11\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size # LATENT_DIM\n",
    "        self.num_layers = num_layers  # 1 or 2\n",
    " \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size) # input size = vocab fr size = num_words_output\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p, batch_first=True)  # -> N x T decoder x hidden\n",
    "        self.fc = nn.Linear(hidden_size, output_size) # ->  N x T x output size\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: (N) where N is for batch size, we want it to be (N, 1), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        x = x.unsqueeze(1) # -> (N, 1)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (N, 1, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # outputs shape: (N, 1, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # predictions shape: (N, 1, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "        predictions = predictions.squeeze(1)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "        # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1c131bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        # source = encoder_inputs\n",
    "        # target = encoder_inputs\n",
    "        batch_size = source.shape[0] # source (N, T_encoder)\n",
    "        target_len = target.shape[1] # target (N, T_decoder)\n",
    "        target_vocab_size = num_words_output # check this is correct num_words = len(word2idx_outputs) + 1 \n",
    "\n",
    "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(device) # (N, T_decoder, vocab)\n",
    "\n",
    "        hidden, cell = self.encoder(source) # (num_layers, hidden_size)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[:,0] # (N, 1)\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            #hidden, cell = hidden.squeeze(1), cell.squeeze(1)\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[:,t,:] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[:,t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53741ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size_encoder = num_words\n",
    "input_size_decoder = num_words_output\n",
    "output_size = num_words_output\n",
    "encoder_embedding_size = EMBEDDING_DIM\n",
    "decoder_embedding_size = EMBEDDING_DIM\n",
    "hidden_size = LATENT_DIM  # Needs to be the same for both RNN's\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 300\n",
    "learning_rate = 0.001\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eee8a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eeb0e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoder_net, decoder_net).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d049655b-7944-4832-bdc6-51bdc5090fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('./translation.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75ddda6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(6091, 100)\n",
       "    (rnn): LSTM(100, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(17860, 100)\n",
       "    (rnn): LSTM(100, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "    (fc): Linear(in_features=256, out_features=17860, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss and optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())#, lr=learning_rate, weight_decay=1e-3)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3323154a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 50]\n",
      "Loss: 2.2200\n",
      "[Epoch 1 / 50]\n",
      "Loss: 2.0264\n",
      "[Epoch 2 / 50]\n",
      "Loss: 1.6159\n",
      "[Epoch 3 / 50]\n",
      "Loss: 1.6062\n",
      "[Epoch 4 / 50]\n",
      "Loss: 1.5242\n",
      "[Epoch 5 / 50]\n",
      "Loss: 1.7400\n",
      "[Epoch 6 / 50]\n",
      "Loss: 1.2838\n",
      "[Epoch 7 / 50]\n",
      "Loss: 1.6582\n",
      "[Epoch 8 / 50]\n",
      "Loss: 1.4400\n",
      "[Epoch 9 / 50]\n",
      "Loss: 1.4825\n",
      "[Epoch 10 / 50]\n",
      "Loss: 1.4067\n",
      "[Epoch 11 / 50]\n",
      "Loss: 1.0943\n",
      "[Epoch 12 / 50]\n",
      "Loss: 1.0234\n",
      "[Epoch 13 / 50]\n",
      "Loss: 1.2690\n",
      "[Epoch 14 / 50]\n",
      "Loss: 1.2933\n",
      "[Epoch 15 / 50]\n",
      "Loss: 1.2088\n",
      "[Epoch 16 / 50]\n",
      "Loss: 1.0734\n",
      "[Epoch 17 / 50]\n",
      "Loss: 1.0536\n",
      "[Epoch 18 / 50]\n",
      "Loss: 1.2210\n",
      "[Epoch 19 / 50]\n",
      "Loss: 1.2157\n",
      "[Epoch 20 / 50]\n",
      "Loss: 0.9527\n",
      "[Epoch 21 / 50]\n",
      "Loss: 0.9808\n",
      "[Epoch 22 / 50]\n",
      "Loss: 1.1917\n",
      "[Epoch 23 / 50]\n",
      "Loss: 1.0818\n",
      "[Epoch 24 / 50]\n",
      "Loss: 0.9600\n",
      "[Epoch 25 / 50]\n",
      "Loss: 1.0902\n",
      "[Epoch 26 / 50]\n",
      "Loss: 1.0358\n",
      "[Epoch 27 / 50]\n",
      "Loss: 0.9822\n",
      "[Epoch 28 / 50]\n",
      "Loss: 1.2579\n",
      "[Epoch 29 / 50]\n",
      "Loss: 1.1025\n",
      "[Epoch 30 / 50]\n",
      "Loss: 1.1055\n",
      "[Epoch 31 / 50]\n",
      "Loss: 1.0346\n",
      "[Epoch 32 / 50]\n",
      "Loss: 0.9254\n",
      "[Epoch 33 / 50]\n",
      "Loss: 0.9248\n",
      "[Epoch 34 / 50]\n",
      "Loss: 0.9578\n",
      "[Epoch 35 / 50]\n",
      "Loss: 1.0845\n",
      "[Epoch 36 / 50]\n",
      "Loss: 1.0227\n",
      "[Epoch 37 / 50]\n",
      "Loss: 1.0604\n",
      "[Epoch 38 / 50]\n",
      "Loss: 0.8973\n",
      "[Epoch 39 / 50]\n",
      "Loss: 1.1785\n",
      "[Epoch 40 / 50]\n",
      "Loss: 1.0910\n",
      "[Epoch 41 / 50]\n",
      "Loss: 0.9976\n",
      "[Epoch 42 / 50]\n",
      "Loss: 0.9504\n",
      "[Epoch 43 / 50]\n",
      "Loss: 1.0167\n",
      "[Epoch 44 / 50]\n",
      "Loss: 0.9957\n",
      "[Epoch 45 / 50]\n",
      "Loss: 0.9120\n",
      "[Epoch 46 / 50]\n",
      "Loss: 1.1910\n",
      "[Epoch 47 / 50]\n",
      "Loss: 0.8971\n",
      "[Epoch 48 / 50]\n",
      "Loss: 0.9243\n",
      "[Epoch 49 / 50]\n",
      "Loss: 0.9608\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I love dogs\"\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "train_losses = np.zeros(num_epochs)\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    #checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    #save_checkpoint(checkpoint)\n",
    "\n",
    "    #model.eval()\n",
    "\n",
    "    \n",
    "    #translated_sentence = translate_sentence(sentence)\n",
    "\n",
    "    #print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "    #model.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        train_loss = []\n",
    "        # Get input and targets and get to cuda\n",
    "        # encoder_in, decoder_in, decoder_out\n",
    "        encoder_in, decoder_in, target = batch\n",
    "        encoder_in, decoder_in, target = encoder_in.to(device), decoder_in.to(device), target.to(device)\n",
    "        #inp_data = batch.src.to(device)\n",
    "        #target = batch.trg.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(encoder_in, decoder_in)\n",
    "\n",
    "        # Output is of shape (batch_size, trg_len, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have batch_size * output_words that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin. While we're at it\n",
    "        # Let's also remove the start token while we're at it\n",
    "        #output = output[1:].reshape(-1, output.shape[2])\n",
    "        #target = target[1:].reshape(-1)\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target.reshape(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target.long())\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    epoch_loss = np.mean(train_loss)           \n",
    "    train_losses[epoch] = epoch_loss\n",
    "    print(f'Loss: {epoch_loss:.4f}')\n",
    "        # Plot to tensorboard\n",
    "        #writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        #step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbcd3e84-445f-4374-824c-8e4351dc78ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# some plots\n",
    "plt.plot(train_losses, label=\"train_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bc144df",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './translation.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ace5940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# map indexes back into real words\n",
    "# so wwe can view the results\n",
    "idx2word_eng = {v: w for w, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v: w for w, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f52db17d-e806-41cf-99a2-dca07f1ae166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # encode the input as state vectors.\n",
    "    input_seq = input_seq.to(device)\n",
    "    with torch.no_grad():\n",
    "        h, c = encoder_net(input_seq)\n",
    "\n",
    "        # generate empty target seq of length 1\n",
    "        target_seq = torch.zeros(1).int().to(device)\n",
    "\n",
    "        # populate the first character of target sequence with the start character\n",
    "        # NOTE: tokenizer lower cases all words\n",
    "        target_seq[0] = word2idx_outputs[\"<sos>\"]\n",
    "\n",
    "        # if we get this we break\n",
    "        eos = word2idx_outputs[\"<eos>\"]\n",
    "\n",
    "        # create translation\n",
    "        output_sentence = []\n",
    "        for _ in range(max_len_target):\n",
    "            output_tokens, h, c = decoder_net(target_seq, h, c)\n",
    "\n",
    "            # get next word\n",
    "            idx = output_tokens.argmax(1).item()\n",
    "\n",
    "            # end of sentence EOS\n",
    "            if eos == idx:\n",
    "                break\n",
    "\n",
    "            word = \"\"\n",
    "            if idx > 0:\n",
    "                word = idx2word_trans[idx]\n",
    "                output_sentence.append(word)\n",
    "\n",
    "            # update the decoder input\n",
    "            # which is just the word just generated\n",
    "            target_seq[0] = idx\n",
    "            #states_value = [h, c]\n",
    "\n",
    "        return \" \".join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d55bba23-35e4-4eb0-a2d4-57c388d17104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: Did you go out?\n",
      "Translation: sortie ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: Thanks for the help.\n",
      "Translation: pour la aide.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: I'm here for good.\n",
      "Translation: suis là pour moment.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: He decided not to go.\n",
      "Translation: a décidé ne pas pas\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: My house was on fire.\n",
      "Translation: voiture était en feu.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: All that has changed.\n",
      "Translation: cela a changé.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: I really need to go.\n",
      "Translation: me vraiment vraiment aller. aller.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: I was ready.\n",
      "Translation: prête.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: It depends on you.\n",
      "Translation: dépend de vous.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: We're the last.\n",
      "Translation: sommes les derniers.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: It'll break.\n",
      "Translation: va se se\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: Can you deliver this?\n",
      "Translation: livrer ceci ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: Tom would cry.\n",
      "Translation: pleurerait.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: You're tough.\n",
      "Translation: es dur.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: Is that understood?\n",
      "Translation: est-il ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: He's a biologist.\n",
      "Translation: est biologiste.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: They went crazy.\n",
      "Translation: devinrent folles.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: Tom is unmoved.\n",
      "Translation: est indifférent.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: The paint's drying.\n",
      "Translation: peinture est en train de sécher.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue? [Y/n] n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # do some translation\n",
    "    i = np.random.choice(len(input_texts))\n",
    "    input_seq = encoder_inputs[i : i + 1]\n",
    "    input_seq = torch.from_numpy(input_seq).to(device)\n",
    "    translation = decode_sequence(input_seq)\n",
    "    print(\"_\")\n",
    "    print(\"Input:\", input_texts[i])\n",
    "    print(\"Translation:\", translation)\n",
    "\n",
    "    ans = input(\"Continue? [Y/n]\")\n",
    "    if ans and ans.lower().startswith(\"n\"):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23e23b00-be25-4b59-8fa0-2fcabd8c8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just som tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ee253-758a-4e54-a12c-4384eea0e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence=\"I love dogs\"):\n",
    "    sentence = [sentence]\n",
    "    print(sentence)\n",
    "    sequence = tokenizer_inputs.texts_to_sequences(sentence)\n",
    "    print(sequence)\n",
    "    sequence = pad_sequences(sequence, maxlen=max_len_input)\n",
    "    print(sequence)\n",
    "    sequence = torch.Tensor(sequence).int()\n",
    "    print(sequence)\n",
    "    translation = decode_sequence(sequence)\n",
    "    print(translation)\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38aa28-65b4-4b9a-8f50-0f37db927994",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I love dogs\"\n",
    "translate_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff9491-34b6-4455-ac62-87a82c12ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [sentence]\n",
    "sequence = tokenizer_inputs.texts_to_sequences(sentence)\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20276f79-a701-4dfe-9d02-10cebc0d9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word_eng[495]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173a508c-dd93-4629-a6af-ca46128c1011",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(len(input_texts))\n",
    "print(i)\n",
    "input_seq = encoder_inputs[i : i + 1]\n",
    "print(input_seq)\n",
    "input_seq = torch.from_numpy(input_seq).to(device)\n",
    "translation = decode_sequence(input_seq)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3b046-6085-4126-827e-a446aee8632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequence)\n",
    "sequence = pad_sequences(sequence, maxlen=max_len_input)\n",
    "print(sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182da0a6-8e09-408a-8442-036d4b1fcfc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
