{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27e24ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df92808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some configuration\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20_000\n",
    "NUM_SAMPLES = 10_000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f4be06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "input_texts = []  # sentence in original language\n",
    "target_texts = []  # sentence in target language\n",
    "target_text_inputs = []  #  sentence in target language offset by 1\n",
    "t = 0\n",
    "for line in open(\"./fra.txt\"):\n",
    "    # only keep a limited number of samples\n",
    "    t += 1\n",
    "    if t > NUM_SAMPLES:\n",
    "        break\n",
    "    line = line.rstrip()\n",
    "    # input and targets are separeted by tab\n",
    "    if \"\\t\" not in line:\n",
    "        continue\n",
    "\n",
    "    # split up the input and translation\n",
    "    input_text, translation = line.split(\"\\t\")[:2]\n",
    "\n",
    "    # make the target input and output\n",
    "    # recall we'll be using teacher forcing\n",
    "    target_text = translation + \" <eos>\"\n",
    "    target_text_input = \"<sos> \" + translation\n",
    "\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    target_text_inputs.append(target_text_input)\n",
    "print(\"num samples:\", len(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4651a080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2033 unique input tokens\n"
     ]
    }
   ],
   "source": [
    "#  tokenize inputs\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "\n",
    "\n",
    "# get word -> integer mapping\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print(\"Found %s unique input tokens\" % len(word2idx_inputs))\n",
    "\n",
    "# determine maximum length input sequence\n",
    "max_len_input = max(len(s) for s in input_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d74c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5680 unique output tokens\n"
     ]
    }
   ],
   "source": [
    "# tokenize outputs\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters=\"\")\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_text_inputs)\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_text_inputs)\n",
    "\n",
    "# get word -> integer mapping for outputs\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print(\"Found %s unique output tokens\" % len(word2idx_outputs))\n",
    "\n",
    "\n",
    "# store number of output wors for later\n",
    "# remember to add 1 since indexing start at 1\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "\n",
    "# determine maximum length output sequence\n",
    "max_len_target = max(len(s) for s in target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf0a3720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_data.shape: (10000, 4)\n",
      "encoder_data[0]: [0 0 0 9]\n",
      "decoder_data.shape: (10000, 11)\n",
      "decoder_data[0]: [ 2 43  4  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_data.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_data[0]:\", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(\n",
    "    target_sequences_inputs, maxlen=max_len_target, padding=\"post\"\n",
    ")\n",
    "print(\"decoder_data.shape:\", decoder_inputs.shape)\n",
    "print(\"decoder_data[0]:\", decoder_inputs[0])\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f883a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word vectors ...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load in pre-trained word vectors\n",
    "print(\"loading word vectors ...\")\n",
    "word2vec_path = '../../Lazyprogrammer/large_files/glove.6B/glove.6B.%sd.txt'\n",
    "word2vec = {}\n",
    "with open(\n",
    "    os.path.join(word2vec_path % EMBEDDING_DIM)\n",
    ") as f:\n",
    "    # is just a space-separated text file in the format:\n",
    "    # word vec[0] vec[1] vec[2]\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.array(values[1:], dtype=\"float32\")\n",
    "        word2vec[word] = vec\n",
    "    print(\"Found %s word vectors.\" % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "909b1ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print(\"Filling pre-trained embeddings...\")\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i < MAX_NUM_WORDS:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all zeros\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89dbdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot the targets (can't use sparse categorical cross entropy)\n",
    "decoder_targets_one_hot = np.zeros(\n",
    "    (len(input_sequences), max_len_target, num_words_output), dtype=\"float32\"\n",
    ")\n",
    "for i, d in enumerate(decoder_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f26677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data set\n",
    "class Translation(data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.encoder_in = torch.from_numpy(encoder_inputs).int()\n",
    "        self.decoder_in = torch.from_numpy(decoder_inputs).int()\n",
    "        self.decoder_out = torch.from_numpy(decoder_targets).float()\n",
    "        #self.decoder_out = torch.from_numpy(decoder_targets_one_hot).float()\n",
    "    def __len__(self):\n",
    "        return len(encoder_inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        encoder_in = self.encoder_in[idx]\n",
    "        decoder_in = self.decoder_in[idx]\n",
    "        decoder_out = self.decoder_out[idx]\n",
    "        \n",
    "    \n",
    "        return encoder_in, decoder_in, decoder_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b00baa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate dataset\n",
    "translation_dataset = Translation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "911971a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=translation_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f23532f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 4]) torch.Size([64, 11]) torch.Size([64, 11])\n"
     ]
    }
   ],
   "source": [
    "for inputs, inputs_d, targets in data_loader:\n",
    "    print(inputs.shape, inputs_d.shape, targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "386f5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word embeddings into an embedding layer\n",
    "# freeze the layer\n",
    "embedding_layer = nn.Embedding(num_words, EMBEDDING_DIM)  # vocab size  # embedding dim\n",
    "embedding_layer.weight = nn.Parameter(torch.from_numpy(embedding_matrix).float())\n",
    "embedding_layer.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de69bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some configuration\n",
    "# EMBEDDING_DIM = 100\n",
    "# LATENT_DIM = 256\n",
    "# T encoder = 4\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size,embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size # LATENT_DIM\n",
    "        self.num_layers = num_layers # 1 or 2\n",
    "\n",
    "        self.embedding = embedding_layer # vocab size x EMBEDDING_DIM\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True,batch_first=True, dropout=p) # -> N x T x 2*hidden\n",
    "\n",
    "        self.fc_hidden = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.fc_cell = nn.Linear(hidden_size*2, hidden_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (N, T encoder) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x)) # (N, T encoder, EMBEDDING_DIM)\n",
    "        # embedding shape: # (N, T encoder, EMBEDDING_DIM)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "        #  outputs shape:  (N, T encoder , hidden_size) \n",
    "        # hidden, cell : (2*num_layers, hidden_size) bidirectional = True\n",
    "        return outputs, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42daaf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_DIM = 100\n",
    "# LATENT_DIM = 256\n",
    "# T decoder = 11\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size # LATENT_DIM\n",
    "        self.num_layers = num_layers  # 1 or 2\n",
    " \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size) # input size = vocab fr size = num_words_output\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p, batch_first=True)  # -> N x T decoder x hidden\n",
    "        self.fc = nn.Linear(hidden_size, output_size) # ->  N x T x output size\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: (N) where N is for batch size, we want it to be (N, 1), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        x = x.unsqueeze(1) # -> (N, 1)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (N, 1, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # outputs shape: (N, 1, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # predictions shape: (N, 1, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "        predictions = predictions.squeeze(1)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "        # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1c131bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        # source = encoder_inputs\n",
    "        # target = encoder_inputs\n",
    "        batch_size = source.shape[0] # source (N, T_encoder)\n",
    "        target_len = target.shape[1] # target (N, T_decoder)\n",
    "        target_vocab_size = num_words_output # check this is correct num_words = len(word2idx_outputs) + 1 \n",
    "\n",
    "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(device) # (N, T_decoder, vocab)\n",
    "\n",
    "        hidden, cell = self.encoder(source) # (num_layers, hidden_size)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[:,0] # (N, 1)\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            #hidden, cell = hidden.squeeze(1), cell.squeeze(1)\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[:,t,:] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[:,t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53741ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "input_size_encoder = num_words\n",
    "input_size_decoder = num_words_output\n",
    "output_size = num_words_output\n",
    "encoder_embedding_size = EMBEDDING_DIM\n",
    "decoder_embedding_size = EMBEDDING_DIM\n",
    "hidden_size = LATENT_DIM  # Needs to be the same for both RNN's\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 300\n",
    "learning_rate = 0.001\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eee8a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eeb0e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoder_net, decoder_net).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d049655b-7944-4832-bdc6-51bdc5090fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./translation.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75ddda6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(2034, 100)\n",
       "    (rnn): LSTM(100, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(5681, 100)\n",
       "    (rnn): LSTM(100, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "    (fc): Linear(in_features=256, out_features=5681, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss and optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())#, lr=learning_rate, weight_decay=1e-3)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc808f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 11, 5681])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, batch in enumerate(data_loader):\n",
    "        train_loss = []\n",
    "        # Get input and targets and get to cuda\n",
    "        # encoder_in, decoder_in, decoder_out\n",
    "        encoder_in, decoder_in, target = batch\n",
    "        encoder_in, decoder_in, target = encoder_in.to(device), decoder_in.to(device), target.to(device)\n",
    "        #inp_data = batch.src.to(device)\n",
    "        #target = batch.trg.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(encoder_in, decoder_in)\n",
    "        print(output.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3323154a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 10]\n",
      "Loss: 1.6442\n",
      "[Epoch 1 / 10]\n",
      "Loss: 1.6549\n",
      "[Epoch 2 / 10]\n",
      "Loss: 1.5233\n",
      "[Epoch 3 / 10]\n",
      "Loss: 1.6814\n",
      "[Epoch 4 / 10]\n",
      "Loss: 1.4400\n",
      "[Epoch 5 / 10]\n",
      "Loss: 1.4640\n",
      "[Epoch 6 / 10]\n",
      "Loss: 1.5420\n",
      "[Epoch 7 / 10]\n",
      "Loss: 1.5404\n",
      "[Epoch 8 / 10]\n",
      "Loss: 1.4931\n",
      "[Epoch 9 / 10]\n",
      "Loss: 1.4342\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I love dogs\"\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses = np.zeros(num_epochs)\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    #checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    #save_checkpoint(checkpoint)\n",
    "\n",
    "    #model.eval()\n",
    "\n",
    "    \n",
    "    #translated_sentence = translate_sentence(sentence)\n",
    "\n",
    "    #print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "    #model.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        train_loss = []\n",
    "        # Get input and targets and get to cuda\n",
    "        # encoder_in, decoder_in, decoder_out\n",
    "        encoder_in, decoder_in, target = batch\n",
    "        encoder_in, decoder_in, target = encoder_in.to(device), decoder_in.to(device), target.to(device)\n",
    "        #inp_data = batch.src.to(device)\n",
    "        #target = batch.trg.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(encoder_in, decoder_in)\n",
    "\n",
    "        # Output is of shape (batch_size, trg_len, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have batch_size * output_words that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin. While we're at it\n",
    "        # Let's also remove the start token while we're at it\n",
    "        #output = output[1:].reshape(-1, output.shape[2])\n",
    "        #target = target[1:].reshape(-1)\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target.reshape(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target.long())\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    epoch_loss = np.mean(train_loss)           \n",
    "    train_losses[epoch] = epoch_loss\n",
    "    print(f'Loss: {epoch_loss:.4f}')\n",
    "        # Plot to tensorboard\n",
    "        #writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        #step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc144df",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './translation.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ace5940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# map indexes back into real words\n",
    "# so wwe can view the results\n",
    "idx2word_eng = {v: w for w, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v: w for w, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f52db17d-e806-41cf-99a2-dca07f1ae166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # encode the input as state vectors.\n",
    "    input_seq = input_seq.to(device)\n",
    "    with torch.no_grad():\n",
    "        h, c = encoder_net(input_seq)\n",
    "\n",
    "        # generate empty target seq of length 1\n",
    "        target_seq = torch.zeros(1).int().to(device)\n",
    "\n",
    "        # populate the first character of target sequence with the start character\n",
    "        # NOTE: tokenizer lower cases all words\n",
    "        target_seq[0] = word2idx_outputs[\"<sos>\"]\n",
    "\n",
    "        # if we get this we break\n",
    "        eos = word2idx_outputs[\"<eos>\"]\n",
    "\n",
    "        # create translation\n",
    "        output_sentence = []\n",
    "        for _ in range(max_len_target):\n",
    "            output_tokens, h, c = decoder_net(target_seq, h, c)\n",
    "\n",
    "            # get next word\n",
    "            idx = output_tokens.argmax(1).item()\n",
    "\n",
    "            # end of sentence EOS\n",
    "            if eos == idx:\n",
    "                break\n",
    "\n",
    "            word = \"\"\n",
    "            if idx > 0:\n",
    "                word = idx2word_trans[idx]\n",
    "                output_sentence.append(word)\n",
    "\n",
    "            # update the decoder input\n",
    "            # which is just the word just generated\n",
    "            target_seq[0] = idx\n",
    "            #states_value = [h, c]\n",
    "\n",
    "        return \" \".join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "055e13eb-41f9-43e8-ba74-3b72cfe99b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        h, c = encoder_net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d55bba23-35e4-4eb0-a2d4-57c388d17104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Input: I'll manage.\n",
      "Translation: va\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: Get real!\n",
      "Translation: à\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: Get inside.\n",
      "Translation: \n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: Help Tom out.\n",
      "Translation: tom\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: Are we lost?\n",
      "Translation: que ?\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: I'll shoot.\n",
      "Translation: va\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: It's all OK.\n",
      "Translation: n'est pas\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: Tom meant it.\n",
      "Translation: m'a\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: Kiss me.\n",
      "Translation: \n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: It was a test.\n",
      "Translation: une d'une\n",
      "Continue? [Y/n]\n",
      "_\n",
      "Input: Keep quiet.\n",
      "Translation: ici.\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # do some translation\n",
    "    i = np.random.choice(len(input_texts))\n",
    "    input_seq = encoder_inputs[i : i + 1]\n",
    "    input_seq = torch.from_numpy(input_seq).to(device)\n",
    "    translation = decode_sequence(input_seq)\n",
    "    print(\"_\")\n",
    "    print(\"Input:\", input_texts[i])\n",
    "    print(\"Translation:\", translation)\n",
    "\n",
    "    ans = input(\"Continue? [Y/n]\")\n",
    "    if ans and ans.lower().startswith(\"n\"):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc7ee253-758a-4e54-a12c-4384eea0e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence=\"I love dogs\"):\n",
    "    sentence = [sentence]\n",
    "    sequence = tokenizer_inputs.texts_to_sequences(sentence)\n",
    "    sequence = torch.Tensor(sequence).int()\n",
    "    translation = decode_sequence(sequence)\n",
    "    print(translation)\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa38aa28-65b4-4b9a-8f50-0f37db927994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demande-leur. c'est jouer cassée jouer jouer manteau. divorcée. appellerai. cassée cassée\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"demande-leur. c'est jouer cassée jouer jouer manteau. divorcée. appellerai. cassée cassée\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5ff9491-34b6-4455-ac62-87a82c12ec28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20276f79-a701-4dfe-9d02-10cebc0d9a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
